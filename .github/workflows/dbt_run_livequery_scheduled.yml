name: dbt_run_livequery_scheduled
run-name: dbt_run_livequery_scheduled

on:
  workflow_dispatch:
  schedule:
    # Runs hourly (see https://crontab.guru)
    - cron: '0 * * * *'

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: "${{ vars.WAREHOUSE }}"
  SCHEMA: "${{ vars.SCHEMA }}"
  PAGODA_API_KEY: "${{ secrets.PAGODA_API_KEY }}"
  PAGODA_SQL_LIMIT: "${{ vars.PAGODA_SQL_LIMIT }}"

concurrency:
  group: ${{ github.workflow }}
  
jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Run LiveQuery Model(s)
        run: |
          dbt run -s tag:pagoda --vars '{"PAGODA_API_KEY": ${{ secrets.PAGODA_API_KEY }}, "SQL_LIMIT": ${{ vars.PAGODA_SQL_LIMIT }}}' 

      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target
