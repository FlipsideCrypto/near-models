name: dbt_run_scheduled_core
run-name: dbt_run_scheduled_core

on:
  workflow_dispatch:
  schedule:
    # Runs "every 20 mins" (see https://crontab.guru)
    - cron: "*/20 * * * *"

env:
  USE_VARS: "${{ vars.USE_VARS }}"
  DBT_PROFILES_DIR: "${{ vars.DBT_PROFILES_DIR }}"
  DBT_VERSION: "${{ vars.DBT_VERSION }}"
  ACCOUNT: "${{ vars.ACCOUNT }}"
  ROLE: "${{ vars.ROLE }}"
  USER: "${{ vars.USER }}"
  PASSWORD: "${{ secrets.PASSWORD }}"
  REGION: "${{ vars.REGION }}"
  DATABASE: "${{ vars.DATABASE }}"
  WAREHOUSE: DBT_CLOUD_LARGE
  SCHEMA: "${{ vars.SCHEMA }}"

concurrency:
  group: ${{ github.workflow }}

jobs:
  dbt:
    runs-on: ubuntu-latest
    environment:
      name: workflow_prod
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: install dependencies
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Call External Table Refresh job in Streamline repository
        run: |
          curl -X POST \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/repos/FlipsideCrypto/streamline-snowflake/dispatches \
            -d '{"event_type":"dbt_run_scheduled_execution"}'

      - name: Run DBT Jobs
        run: |
          dbt run-operation dispatch_github_workflow --args "{'repo_name': 'streamline-snowflake', 'workflow_name': 'dbt_run_near_external_table_update', 'gb_id': '${{ secrets.GB_ID}}'}";
          dbt seed;
          dbt run -s tag:scheduled_core tag:grail --vars "{ 'RECEIPT_MAP_LOOKBACK_HOURS': 0.5}";
      - name: Store logs
        uses: actions/upload-artifact@v3
        with:
          name: dbt-logs
          path: |
            logs
            target
